{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4b28c6-5a61-4fd2-beb1-7c58a4c6ed56",
   "metadata": {},
   "source": [
    "# Data consistency\n",
    "What we did so far was looking at each Dataframe individually. Now it's time to look at all Dataframes and see if the information we have is consistent. This include things like\n",
    "\n",
    "- Are huge price differences explainable with discounts etc. when comparing the prices in the products df and the orders df?\n",
    "- Is every product ordered present in the products table? \n",
    "- Are there significant datetime differences?\n",
    "\n",
    "If we do not have a solution to inconsistencies that might arise, we'll have to get rid of inconsistent data. At the end of this notebook we want to have merged our tables into one big dataframe, which has all the information we need for our data analysis and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c396e96f-c0a7-4f9b-b998-0ae462c7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0404023-8028-4c10-a2e4-563b11469c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec8a281-d8c0-4ac0-82ed-bd5612d319b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.read_csv('data/brands.csv')\n",
    "orders = pd.read_csv('data/orders_clean.csv', parse_dates=['created_date'])\n",
    "orderlines = pd.read_csv('data/orderlines_clean.csv', parse_dates=['date'])\n",
    "products = pd.read_csv('data/products_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c9d94-e498-4033-a182-c1d03b24540e",
   "metadata": {},
   "source": [
    "Note that we have to tell pandas which columns should be treated as datetimes. Otherwise the dtype of our columns would have been `object`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61e795-be97-4e7f-97b8-d57ec96c3e0c",
   "metadata": {},
   "source": [
    "## Inconsistencies regarding the sku\n",
    "\n",
    "We want to exclude orders which contain products that do not appear in the products list.\n",
    "Since orderlines also has a sku column, we can compare the orderlines and products df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2659418d-4c9f-4aed-b91f-d1ff270257cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orderlines['check_products'] = ~orderlines.sku.isin(products.sku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b98c07-5761-48ce-bf5f-c40807f595d3",
   "metadata": {},
   "source": [
    "Now we should remove every id_order, that contains a product that is not in the list.\n",
    "Note that every row with such an id_order should be removed, not only the ones with a non-existing sku.\n",
    "To do this we can create a new table orderlines_id_remove, which is grouped by the id_order and aggregates the False-counts of check_products. If the count is >0, we remove that id_order.\n",
    "To make life a little easier, I change the check_products column for this: It says True if the sku is NOT in the product list.\n",
    "Now we can sum up easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e31e106-94c6-4035-85dc-57df63f46b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orderlines_id_remove = orderlines.copy().groupby('id_order').agg({'check_products':'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a38a1-6ae4-4ff7-8c36-1e036178e940",
   "metadata": {},
   "source": [
    "We keep only those id_orders, where orderlines_id_remove.check_products == 0.\n",
    "We also reset the index, so that we don't get a key error in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7cb4d8-bcb1-4956-bc28-e87c86ff5b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orderlines_id_remove = orderlines_id_remove.loc[orderlines_id_remove.check_products == 0].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02cc96-2683-44bf-a49e-839ee8636100",
   "metadata": {},
   "source": [
    "Now we only keep those rows from orderlines, that have an id_order, that appears in orderlines_id_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98a2912-3f57-4e39-9932-f0110bbd7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderlines = orderlines.loc[orderlines.id_order.isin(orderlines_id_remove.id_order)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d69848-7f94-457e-8d4b-0c4e525c6589",
   "metadata": {},
   "source": [
    "Since id_orders should match orders.order_id, we also remove rows from orders and orderlines whose id does not appear in both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7aecb24-eded-4ac1-82ce-250acb855133",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.loc[orders.order_id.isin(orderlines.id_order)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0086a35d-38dd-4029-b76f-82000730a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderlines = orderlines.loc[orderlines.id_order.isin(orders.order_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02216e-9567-4c32-b4f5-77062ee557b2",
   "metadata": {},
   "source": [
    "We don't need the column 'check_products' anymore, so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcb89b8-b7dc-43be-a3c6-67563e54ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderlines.drop(columns=['check_products'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76587954-325e-490d-936a-abd98dbe2f20",
   "metadata": {},
   "source": [
    "## Merging tables\n",
    "\n",
    "We'll now merge the tables at investigate further inconsistencies afterwards.\n",
    "Since orderlines and products share the sku column and the order_id's from orders and orderlines match, joining these tables don't pose any difficulties. For merging the brands table, we need to create a column with the first 3 characters of the sku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95e6029-42a6-438d-9408-5d93541e442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_quantity</th>\n",
       "      <th>sku</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>date</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1119109</td>\n",
       "      <td>299539</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>OTT0133</td>\n",
       "      <td>18.99</td>\n",
       "      <td>2017-01-01 00:07:19</td>\n",
       "      <td>OTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1119110</td>\n",
       "      <td>299540</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>LGE0043</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2017-01-01 00:19:45</td>\n",
       "      <td>LGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1119111</td>\n",
       "      <td>299541</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAR0071</td>\n",
       "      <td>474.05</td>\n",
       "      <td>2017-01-01 00:20:57</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119112</td>\n",
       "      <td>299542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WDT0315</td>\n",
       "      <td>68.39</td>\n",
       "      <td>2017-01-01 00:51:40</td>\n",
       "      <td>WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1119113</td>\n",
       "      <td>299543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>JBL0104</td>\n",
       "      <td>23.74</td>\n",
       "      <td>2017-01-01 01:06:38</td>\n",
       "      <td>JBL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  id_order  product_id  product_quantity      sku  unit_price  \\\n",
       "0  1119109    299539           0                 1  OTT0133       18.99   \n",
       "1  1119110    299540           0                 1  LGE0043      399.00   \n",
       "2  1119111    299541           0                 1  PAR0071      474.05   \n",
       "3  1119112    299542           0                 1  WDT0315       68.39   \n",
       "4  1119113    299543           0                 1  JBL0104       23.74   \n",
       "\n",
       "                 date short  \n",
       "0 2017-01-01 00:07:19   OTT  \n",
       "1 2017-01-01 00:19:45   LGE  \n",
       "2 2017-01-01 00:20:57   PAR  \n",
       "3 2017-01-01 00:51:40   WDT  \n",
       "4 2017-01-01 01:06:38   JBL  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderlines['short'] = orderlines.sku.str[:3]\n",
    "orderlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d6693-c119-4c4a-864d-dafea78b1d6a",
   "metadata": {},
   "source": [
    "Now we can create our big dataframe, which we will simply call df.\n",
    "All the merging could have been done in one step. We split it here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab4b46a-9a96-41b4-bfed-48bd06fa1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(orderlines, products, how = 'left', on='sku')\n",
    "df = df.merge(orders, how='left', left_on='id_order', right_on='order_id')\n",
    "df = df.merge(brands, how='left', on='short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123a4be4-4f5f-4c80-bb5f-03cafe2bc24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290588 entries, 0 to 290587\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   id                290588 non-null  int64         \n",
      " 1   id_order          290588 non-null  int64         \n",
      " 2   product_id        290588 non-null  int64         \n",
      " 3   product_quantity  290588 non-null  int64         \n",
      " 4   sku               290588 non-null  object        \n",
      " 5   unit_price        290588 non-null  float64       \n",
      " 6   date              290588 non-null  datetime64[ns]\n",
      " 7   short             290588 non-null  object        \n",
      " 8   name              290588 non-null  object        \n",
      " 9   desc              290588 non-null  object        \n",
      " 10  price             290588 non-null  float64       \n",
      " 11  promo_price       290588 non-null  float64       \n",
      " 12  in_stock          290588 non-null  int64         \n",
      " 13  type              290588 non-null  object        \n",
      " 14  order_id          290588 non-null  int64         \n",
      " 15  created_date      290588 non-null  datetime64[ns]\n",
      " 16  total_paid        290582 non-null  float64       \n",
      " 17  state             290588 non-null  object        \n",
      " 18  long              290300 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(4), int64(6), object(7)\n",
      "memory usage: 44.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685c7ff-98e6-46e2-8bbf-2370ab740caa",
   "metadata": {},
   "source": [
    "One thing we notice is that the long column, which stores the brand name, seems to have missing values. \n",
    "With some research we could impute the missing values with the help of the short column by hand. It isn't really needed for our analysis later though, since 288 rows do not really have an impact. For now we'll take the 'short' name as the brand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ff9ae-00c4-41d6-9f3e-1f238bdbab02",
   "metadata": {},
   "source": [
    "Then we'll rename columns like `long` to `brand` and drop multiple columns and columns not needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b691d63b-8ad0-4f25-9160-af0ab8a53ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'long':'brand', 'product_quantity': 'qty'},axis=1, inplace= True)\n",
    "df.loc[df.brand.isna(), 'brand'] = df.loc[df.brand.isna(), 'short'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77304e64-749a-4c3c-b59a-95400838fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['order_id', 'promo_price', 'short', 'sku', 'product_id', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f442254-d390-407e-be57-bb9654355699",
   "metadata": {},
   "source": [
    "## Looking at dates\n",
    "Now that we have our complete dataframe in place, we can start fixing some other issues or remove some outliers that might appear.\n",
    "\n",
    "We'll first look into the dates. Remember that we have two date columns: \n",
    "- `date` from orderlines\n",
    "- `created_date` from orders\n",
    "\n",
    "It was already mentioned that a possible explanation for eventual date differences might be: created_date fixes the time when the first step in the ordering process starts (adding items to the shopping basket), while date refers to the time the order was completed (like confirm to buy the selected items)\n",
    "Following this logic the created_date should always be an earlier point in time. Let's look at the date difference and see if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51972061-6e85-470b-9bac-e050cef992e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_diff'] = df['date']-df['created_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43adb41d-4be2-4401-858d-0f71bc90762c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       290588\n",
       "mean     0 days 04:57:51.118576816\n",
       "std      6 days 07:46:38.783192706\n",
       "min            -239 days +04:59:01\n",
       "25%              -1 days +23:56:42\n",
       "50%                0 days 00:00:00\n",
       "75%                0 days 00:00:00\n",
       "max              397 days 03:11:31\n",
       "Name: date_diff, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date_diff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a11be6-b4c4-4479-8ebb-26792641c76c",
   "metadata": {},
   "source": [
    "It looks like the guess was wrong. Since it isn't clear what the difference is, we'll just remove some outliers (which might be due to some connection/server issues) and afterwards keep only one of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20af1ba6-422f-4edf-b757-c9d4c989dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290588 entries, 0 to 290587\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype          \n",
      "---  ------        --------------   -----          \n",
      " 0   id_order      290588 non-null  int64          \n",
      " 1   qty           290588 non-null  int64          \n",
      " 2   unit_price    290588 non-null  float64        \n",
      " 3   date          290588 non-null  datetime64[ns] \n",
      " 4   name          290588 non-null  object         \n",
      " 5   desc          290588 non-null  object         \n",
      " 6   price         290588 non-null  float64        \n",
      " 7   in_stock      290588 non-null  int64          \n",
      " 8   type          290588 non-null  object         \n",
      " 9   created_date  290588 non-null  datetime64[ns] \n",
      " 10  total_paid    290582 non-null  float64        \n",
      " 11  state         290588 non-null  object         \n",
      " 12  brand         290588 non-null  object         \n",
      " 13  date_diff     290588 non-null  timedelta64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), int64(3), object(5), timedelta64[ns](1)\n",
      "memory usage: 33.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e75995d3-63b6-4dd3-994d-dd4bf02e363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6bf5b9a-baf1-450a-80b0-d4b014021412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date_diff = df.groupby('id_order').aggregate({'date_diff':['max', 'min'], 'id_order':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72179a63-5fe3-4416-8e07-177ca02d50c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id_order</th>\n",
       "      <th colspan=\"2\" halign=\"left\">date_diff</th>\n",
       "      <th>id_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203311.00</td>\n",
       "      <td>203311</td>\n",
       "      <td>203311</td>\n",
       "      <td>203311.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>412952.13</td>\n",
       "      <td>0 days 05:08:53.290446655</td>\n",
       "      <td>0 days 02:55:30.273880901</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65986.70</td>\n",
       "      <td>5 days 21:08:24.044878576</td>\n",
       "      <td>5 days 17:05:12.823665286</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>241319.00</td>\n",
       "      <td>-217 days +06:24:56</td>\n",
       "      <td>-239 days +04:59:01</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>355413.50</td>\n",
       "      <td>-1 days +23:56:25</td>\n",
       "      <td>-1 days +23:56:02</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>412832.00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>469925.50</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>527401.00</td>\n",
       "      <td>397 days 03:11:31</td>\n",
       "      <td>397 days 03:11:31</td>\n",
       "      <td>140.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_order                  date_diff                             \\\n",
       "                                       max                        min   \n",
       "count 203311.00                     203311                     203311   \n",
       "mean  412952.13  0 days 05:08:53.290446655  0 days 02:55:30.273880901   \n",
       "std    65986.70  5 days 21:08:24.044878576  5 days 17:05:12.823665286   \n",
       "min   241319.00        -217 days +06:24:56        -239 days +04:59:01   \n",
       "25%   355413.50          -1 days +23:56:25          -1 days +23:56:02   \n",
       "50%   412832.00            0 days 00:00:00            0 days 00:00:00   \n",
       "75%   469925.50            0 days 00:00:00            0 days 00:00:00   \n",
       "max   527401.00          397 days 03:11:31          397 days 03:11:31   \n",
       "\n",
       "       id_order  \n",
       "          count  \n",
       "count 203311.00  \n",
       "mean       1.43  \n",
       "std        1.07  \n",
       "min        1.00  \n",
       "25%        1.00  \n",
       "50%        1.00  \n",
       "75%        1.00  \n",
       "max      140.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date_diff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e3ed2-b3c5-462c-a523-d8abf5a56998",
   "metadata": {},
   "source": [
    "Here we also see that the time difference does not only happen to orders that consist of more than one product. We'll now save only the `id_order`s with a date_diff of at least one day. We lose about 2% of our orders, but as we might want to do a time analysis we'll rather prioritize time consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e96383-82dc-450b-99a3-5ee73e2ea293",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_date_diff = df.loc[abs(df.date_diff) > timedelta(days=1)].id_order.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bff915a-0031-48ff-a832-e1311623e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df.id_order.isin(id_date_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fea1907d-fd69-49b9-8f72-f740c64753e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['created_date', 'date_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd4d13-1d20-4083-9da7-5e2a9ae9c59e",
   "metadata": {},
   "source": [
    "## Prices\n",
    "Let's look at prices again. Having all of our information in one table we can compare\n",
    "- What was / is to be paid with what the total price of the bought products is. If we find that much more is paid than the actual cost, we might have corrupted data. \n",
    "- price of the products with prices according to the products table. Here we can detect e.g. discounts\n",
    "\n",
    "To make these types of comparisons, we'll define a new column `total_price` of an order with the help of an auxiliary table for aggregation as well as a `disc_perc` column, which catches the discount compared to the price from the products table in percent.\n",
    "\n",
    "Furthermore to guarantee consistence we'll make the auxiliary columns \n",
    "- `price_prod`: contains the product of all the items' prices of an order. If this value is 0 it means that a product doesn't cost anything. For the sake of reliable data we will drop those orders.\n",
    "- `payment_diff`: The quotient of `total_paid` and `total_price`. High numbers mean that the payment was way higher than the actual price. We'll get rid of orders which have a suspicuous relation between the payment and the price.\n",
    "\n",
    "#### Prepare the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b75a81a-3fa4-4b16-a93d-acc23fb068e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['unit_qty_price'] = df['unit_price'] * df['qty'] #auxiliary column\n",
    "\n",
    "df['disc_perc'] = (1- (df['unit_price'] / df['price']))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa76c313-d9f3-4eac-96dc-5f2813e3da2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_multi = pd.DataFrame(df.groupby('id_order').agg({'unit_qty_price':['sum', 'prod']})) # auxiliary table\n",
    "# rename columns and prepare merging \n",
    "d = {'sum':'total_price','prod':'price_prod'}\n",
    "df_multi.columns = df_multi.columns.droplevel(0)\n",
    "df_multi = df_multi.rename(columns = d).reset_index()\n",
    "\n",
    "df = pd.merge(df_multi, df, how='right', on='id_order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb29f2c-a564-4fd8-8c35-a3ec2f77a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_diff'] = df['total_paid'] / df['total_price'] # auxiliary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b7e3bdd-6c24-4f49-9566-f6bedd74af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['unit_qty_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a17ae6-f89f-4c4d-b57c-dc13cdff4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id_order', 'brand', 'name', 'desc', \n",
    "        'total_paid', 'total_price', 'price', 'unit_price', 'disc_perc', 'qty',\n",
    "        'date', 'state', 'in_stock', 'type', 'price_prod', 'payment_diff']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f7f89-b59e-4f14-967b-e7044c5eddd3",
   "metadata": {},
   "source": [
    "#### Find inconsistencies and drop columns\n",
    "\n",
    "Time to make our new columns work for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc4c1c-3c6f-4116-bf19-6828b4f95120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
